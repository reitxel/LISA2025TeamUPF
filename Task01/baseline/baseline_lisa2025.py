# -*- coding: utf-8 -*-
"""LISA2025_QC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Op7MvbjDBoO7yQRRV9aKmb__HouBkzp0
"""

import os
import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import StratifiedGroupKFold
from torch.utils.tensorboard import SummaryWriter
import monai
from monai.data import decollate_batch, DataLoader

from monai.transforms import (
    Activations,
    AsDiscrete,
    Compose,
    SpatialPadd,
    LoadImaged,
    RandAffined,
    RandShiftIntensityd,
    RandGaussianNoised,
    RandRotated,
    CenterSpatialCropd,
    RandAdjustContrastd,
    NormalizeIntensityd,
    ToTensord,
    EnsureChannelFirstd,
    Rand3DElasticd,
    RandFlipd,
    RandScaleIntensityd,
    RandBiasFieldd,
    RandGibbsNoised,
    RandKSpaceSpikeNoised,
)

from typing import Tuple

from torchmetrics.classification import (
    MulticlassPrecision, MulticlassRecall, MulticlassF1Score
)

# Set your data root directory (update this to your actual path in Google Drive)
DATA_ROOT = 'data/LISA2025'
RESULTS_DIR = "baseline/results_aug_FINAL"

# create folder RESULTS_dir if not exists
if not os.path.exists(RESULTS_DIR):
    os.makedirs(RESULTS_DIR)

# Configuration parameters
bids_dir = f"{DATA_ROOT}/BIDS_norm"
qc_csv_path = f"{bids_dir}/LISA_2025_bids.csv"
augmented_dir = f"{bids_dir}/derivatives/augmented_FINAL_Distortion"
augmented_qc_csv_path = (
    f"{bids_dir}/derivatives/augmented_FINAL_Distortion/"
    f"augmented_labels.csv"
)
spatial_size = (150, 150, 150)  # Fixed tuple instead of separate variables
batch_size = 8
random_state = 42
n_classes = 3
n_epoch = 80
lr = 1e-5

offline_augmentation = True
online_augmentation = True

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

list_of_tasks = [
    "Zipper", "Positioning", "Noise", "Banding",
    "Motion", "Contrast", "Distortion"
]


def get_transforms_specific(
    spatial_size: Tuple[int, int, int],
    stage: str = "train",
    class_name: str = None
) -> Compose:
    """
    Get task-specific data transforms for training or validation.
    """
    base_transforms = [
        LoadImaged(keys=["img"], reader="nibabelreader"),
        EnsureChannelFirstd(keys=["img"]),
        NormalizeIntensityd(keys=["img"], nonzero=False, channel_wise=True),
    ]
    
    if stage == "train" and class_name is not None:
        # Define intensity augmentations
        intensity_augs = [
            RandAdjustContrastd(keys=["img"], prob=0.3, gamma=(0.8, 1.2)),
            RandShiftIntensityd(keys=["img"], prob=0.3, offsets=0.1),
            RandScaleIntensityd(keys=["img"], prob=0.3, factors=0.15),
            RandBiasFieldd(
                keys=["img"], prob=0.2, degree=3, coeff_range=(0.0, 0.1)
            ),
            RandGaussianNoised(keys=["img"], prob=0.2, std=0.05),
            RandGibbsNoised(keys=["img"], prob=0.15, alpha=(0.0, 1.0)),
            RandKSpaceSpikeNoised(
                keys=["img"], prob=0.15, intensity_range=(0.9, 1.1)
            ),
        ]
        
        # Define spatial augmentations (conservative)
        spatial_augs = [
            RandFlipd(keys=["img"], prob=0.3, spatial_axis=[0, 1, 2]),
            RandRotated(
                keys=["img"], prob=0.4,
                range_x=0.1, range_y=0.1, range_z=0.05,  # Reduced rotation
                mode="bilinear", padding_mode="border"
            ),
            RandAffined(
                keys=["img"], prob=0.3,  # Reduced probability
                scale_range=(0.05, 0.05, 0.02),  # Much smaller scaling
                translate_range=(3, 3, 2),  # Smaller translation
                mode="bilinear", padding_mode="border"
            ),
        ]
        
        # Very conservative elastic deformation (only for specific tasks)
        mild_elastic = [
            Rand3DElasticd(
                keys=["img"], prob=0.1,  # Very low probability
                sigma_range=(8, 12),     # Smoother deformation
                magnitude_range=(0.5, 1.0),  # Much smaller magnitude
                mode="bilinear", padding_mode="border"
            ),
        ]
        
        # Task-specific augmentation selection
        if class_name == "Noise":
            # Only spatial - avoid noise augmentations
            aug_transforms = spatial_augs
            
        elif class_name == "Zipper":
            # Spatial + very mild intensity + rare elastic
            # (zipper can have slight geometric component)
            safe_intensity = [
                RandAdjustContrastd(keys=["img"], prob=0.2, gamma=(0.9, 1.1)),
                RandShiftIntensityd(keys=["img"], prob=0.2, offsets=0.05),
            ]
            aug_transforms = spatial_augs + safe_intensity + mild_elastic
            
        elif class_name == "Positioning":
            # Only intensity - NO spatial transforms that change positioning
            aug_transforms = intensity_augs
            
        elif class_name == "Banding":
            # Only spatial - avoid intensity changes
            aug_transforms = spatial_augs
            
        elif class_name == "Motion":
            # Only intensity - NO spatial transforms that simulate motion
            aug_transforms = intensity_augs
            
        elif class_name == "Contrast":
            # Only spatial - NO contrast/intensity modifications
            aug_transforms = spatial_augs
            
        elif class_name == "Distortion":
            # Only intensity - NO spatial distortions
            aug_transforms = intensity_augs
            
        else:
            # Fallback: conservative combination
            aug_transforms = intensity_augs + spatial_augs
        
        transforms = base_transforms + aug_transforms + [
            CenterSpatialCropd(keys=["img"], roi_size=spatial_size),
            SpatialPadd(
                keys=["img"], method="symmetric", spatial_size=spatial_size
            ),
            ToTensord(keys=["img"], dtype=torch.float32),
        ]
        
    else:
        transforms = base_transforms + [
            CenterSpatialCropd(keys=["img"], roi_size=spatial_size),
            SpatialPadd(
                keys=["img"], method="symmetric", spatial_size=spatial_size
            ),
            ToTensord(keys=["img"], dtype=torch.float32)
        ]
    
    return Compose(transforms)


def prepare_data(
    class_name: str,
    bids_dir: str,
    qc_csv_path: str,
    augmented_dir: str,
    augmented_qc_csv_path: str,
    random_state: int = 42
):
    """
    Prepare data for training, handling the ordinal nature and class imbalance.
    Returns:
        train_files: list of dicts with keys 'img', 'label', 'subject'
        val_files: list of dicts with keys 'img', 'label', 'subject'
        class_weights: torch.Tensor or np.ndarray (if torch not installed)
    """
    # Load raw and augmented data
    qc_df = pd.read_csv(qc_csv_path)
    qc_df["data_type"] = "raw"
    print("Raw samples: ", len(qc_df))
    aug_qc_df = pd.read_csv(augmented_qc_csv_path)
    aug_qc_df["data_type"] = "augmented"
    print("Augmented samples: ", len(aug_qc_df))

    # Combine dataframes
    combined_df = pd.concat([qc_df, aug_qc_df], ignore_index=True)
    print("Combined samples: ", len(combined_df))
    combined_df = combined_df[combined_df['filename'].notna()]
    print("Combined samples after filtering: ", len(combined_df))

    # Filter for specific task (single-task learning, allow at most one other
    # task labeled as 1 or 2)
    current_task_mask = (
        (combined_df[class_name].notna()) & 
        (combined_df[class_name].isin([0, 1, 2]))
    )
    combined_df = combined_df[current_task_mask]

    if not offline_augmentation:
        combined_df = combined_df[combined_df['data_type'] == 'raw']
    else:
        combined_df = combined_df[combined_df['data_type'] == 'augmented']

    print(f"Number of samples for {class_name}: {len(combined_df)}")
    print(combined_df.head())
    # Print columns
    print(combined_df.columns)

    # Extract data
    filenames = combined_df['filename'].astype(str).values

    labels = combined_df[class_name].values.astype(int)

    # subjects is the first part of the basename of the filenames,
    # being sub-XXXX
    subjects = [
        os.path.basename(filename).split('_')[0]
        for filename in filenames
    ]

    # Create stratified splits ensuring no data leakage between subjects
    sgkf = StratifiedGroupKFold(
        n_splits=5, shuffle=True, random_state=random_state
    )

    # Get first fold for train/val split
    train_idx, val_idx = next(sgkf.split(filenames, labels, subjects))

    # Create data dictionaries
    train_files = [
        {"img": filenames[i], "label": labels[i], "subject": subjects[i]}
        for i in train_idx
    ]
    val_files = [
        {"img": filenames[i], "label": labels[i], "subject": subjects[i]}
        for i in val_idx
    ]

    # Print the amount and label distribution of the train and val sets
    print(f"\nTrain set distribution for {class_name}:")
    train_df = pd.DataFrame(train_files)
    print(train_df['label'].value_counts())
    print(f"\nVal set distribution for {class_name}:")
    val_df = pd.DataFrame(val_files)
    print(val_df['label'].value_counts())

    return train_files, val_files


def metrics_func(probability_tensors, true_tensor):
    true_classes = [
        torch.argmax(label) for label in true_tensor
    ]
    probability_classes = [
        torch.argmax(label) for label in probability_tensors
    ]

    true_combined_tensor = torch.tensor(
        [t.item() for t in true_classes]
    )
    prob_combined_tensor = torch.tensor(
        [t.item() for t in probability_classes]
    )

    # Initialize metric calculators
    # Use the weighted to handle the imbalance labels
    precision_metric = MulticlassPrecision(
        average='weighted', num_classes=3
    )
    recall_metric = MulticlassRecall(
        average='weighted', num_classes=3
    )
    f1_metric = MulticlassF1Score(
        average='weighted', num_classes=3
    )

    precision_metric.update(prob_combined_tensor, true_combined_tensor)
    recall_metric.update(prob_combined_tensor, true_combined_tensor)
    f1_metric.update(prob_combined_tensor, true_combined_tensor)

    recall = recall_metric.compute()
    f1_value = f1_metric.compute()
    precision = precision_metric.compute()

    # Print other metrics, but just return f1-score
    # Switch to another one, as preferred
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1 Score: {f1_value:.4f}')

    return f1_value


# Define transforms for image
train_transforms = Compose([
    LoadImaged(keys=["img"], reader="nibabelreader"),
    EnsureChannelFirstd(keys=["img"]),
    NormalizeIntensityd(
        keys=["img"], nonzero=False, channel_wise=True
    ),
    CenterSpatialCropd(keys=["img"], roi_size=spatial_size),
    SpatialPadd(
        keys=["img"], method="symmetric", spatial_size=spatial_size
    ),
    ToTensord(keys=["img"]),
])

val_transforms = Compose([
    LoadImaged(keys=["img"], reader="nibabelreader"),
    EnsureChannelFirstd(keys=["img"]),
    NormalizeIntensityd(keys=["img"], nonzero=False, channel_wise=True),
    SpatialPadd(
        keys=["img"], method="symmetric", spatial_size=spatial_size
    ),
    ToTensord(keys=["img"]),
])

post_pred = Compose([Activations(softmax=True)])
post_label = Compose([AsDiscrete(to_onehot=n_classes)])

# MAIN LOOP
for class_name in list_of_tasks:
    train_files, val_files = prepare_data(
        class_name, bids_dir, qc_csv_path, augmented_dir,
        augmented_qc_csv_path, random_state
    )

    check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)
    check_loader = DataLoader(
        check_ds, batch_size=2, num_workers=0,
        pin_memory=torch.cuda.is_available()
    )
    check_data = monai.utils.misc.first(check_loader)
    print(check_data["img"].shape, check_data["label"])

    if online_augmentation:
        train_transforms = get_transforms_specific(
            spatial_size=spatial_size, stage="train", class_name=class_name
        )
        val_transforms = get_transforms_specific(
            spatial_size=spatial_size, stage="val", class_name=class_name
        )

    # create a training data loader
    train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)
    train_loader = DataLoader(
        train_ds, batch_size=batch_size, shuffle=False, num_workers=0,
        pin_memory=torch.cuda.is_available()
    )

    # create a validation data loader
    val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)
    val_loader = DataLoader(
        val_ds, batch_size=batch_size, num_workers=0,
        pin_memory=torch.cuda.is_available()
    )

    model = monai.networks.nets.DenseNet264(
        spatial_dims=3, in_channels=1, out_channels=n_classes
    ).to(device)

    loss_function = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr)

    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=n_epoch
    )

    # start a typical PyTorch training
    val_interval = 1
    best_metric = -1
    best_metric_epoch = -1
    writer = SummaryWriter(log_dir=f"{RESULTS_DIR}/logs")

    epoch_loss_values = []
    metric_values = []

    for epoch in range(n_epoch):
        print("-" * 10)
        print(f"epoch {epoch + 1}/{n_epoch}")
        model.train()
        epoch_loss = 0
        step = 0
        for batch_data in train_loader:
            step += 1
            inputs, labels = (
                batch_data["img"].to(device), 
                batch_data["label"].to(device)
            )
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = loss_function(outputs, labels)
            loss.backward()
            optimizer.step()
            epoch_loss += loss.item()
            epoch_len = len(train_ds) // train_loader.batch_size
            if step % 10 == 0:
                print(f"{step}/{epoch_len}, train_loss: {loss.item():.4f}")
            writer.add_scalar(
                "train_loss", loss.item(), epoch_len * epoch + step
            )

        lr_scheduler.step()
        epoch_loss /= step
        epoch_loss_values.append(epoch_loss)
        print(f"epoch {epoch + 1} average loss: {epoch_loss:.4f}")

        if (epoch + 1) % val_interval == 0:
            model.eval()
            with torch.no_grad():
                y_pred = torch.tensor([], dtype=torch.float32, device=device)
                y = torch.tensor([], dtype=torch.long, device=device)
                for val_data in val_loader:
                    val_images, val_labels = (
                        val_data["img"].to(device), 
                        val_data["label"].to(device)
                    )
                    y_pred = torch.cat([y_pred, model(val_images)], dim=0)
                    y = torch.cat([y, val_labels], dim=0)

                y_onehot = [
                    post_label(i) for i in decollate_batch(y, detach=False)
                ]
                y_pred_act = [post_pred(i) for i in decollate_batch(y_pred)]

                metric_result = metrics_func(y_pred_act, y_onehot)

                metric_values.append(metric_result.item())

                del y_pred_act, y_onehot
                if metric_result >= best_metric:
                    best_metric = metric_result
                    best_metric_epoch = epoch + 1
                    torch.save(
                        model.state_dict(), 
                        f"{RESULTS_DIR}/best_metric_model_LISA_LF_"
                        f"{class_name}.pth"
                    )
                    print("saved new best metric model")
                print(
                    "current epoch: {} current F1-score: {:.4f} "
                    "best F1-score: {:.4f} at epoch {}".format(
                        epoch + 1, metric_result, best_metric,
                        best_metric_epoch
                    )
                )
                writer.add_scalar("val_auc", metric_result, epoch + 1)

        np.save(f"{RESULTS_DIR}/loss_tr_{class_name}.npy", epoch_loss_values)
        np.save(f"{RESULTS_DIR}/val_mean_{class_name}.npy", metric_values)

    print(
        f"train completed, best_metric: {best_metric:.4f} "
        f"at epoch: {best_metric_epoch}"
    )
    writer.close()